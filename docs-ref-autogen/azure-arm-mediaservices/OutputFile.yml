### YamlMime:UniversalReference
ms.openlocfilehash: f4ecb7ab933b794f77479de848453841eb3da99c
ms.sourcegitcommit: ce76ec3eda83746ef9a765165173b5c00b5b7df6
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 12/20/2018
ms.locfileid: "53664088"
items:
- uid: azure-arm-mediaservices.OutputFile
  name: OutputFile
  fullName: OutputFile
  children:
  - azure-arm-mediaservices.OutputFile.labels
  langs:
  - typeScript
  type: interface
  summary: <span data-ttu-id="e750e-101">Представляет созданный выходной файл.</span><span class="sxs-lookup"><span data-stu-id="e750e-101">Represents an output file produced.</span></span>
  package: azure-arm-mediaservices
- uid: azure-arm-mediaservices.OutputFile.labels
  name: labels
  fullName: labels
  children: []
  langs:
  - typeScript
  type: property
  summary: <span data-ttu-id="e750e-102">Список меток, которые описывают, как кодировщик должен мультиплексировать видео и аудио в выходной файл.</span><span class="sxs-lookup"><span data-stu-id="e750e-102">The list of labels that describe how the encoder should multiplex video and audio into an output file.</span></span> <span data-ttu-id="e750e-103">Например если кодировщик создает два уровня видео с помощью меток v1 и v2 и один звуковой слой с a1 метки, массив, например «[v1, a1]» сообщает кодировщику для создания выходного файла с видеодорожки, представленного v1 и звуковую дорожку, представленный a1.</span><span class="sxs-lookup"><span data-stu-id="e750e-103">For example, if the encoder is producing two video layers with labels v1 and v2, and one audio layer with label a1, then an array like '[v1, a1]' tells the encoder to produce an output file with the video track represented by v1 and the audio track represented by a1.</span></span>
  optional: true
  syntax:
    content: 'labels?: string[]'
    return:
      type:
      - string[]
  package: azure-arm-mediaservices
